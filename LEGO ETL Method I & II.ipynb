{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "064775b0-4de8-492a-8e96-764f0bfaad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe38209-9353-4467-a4ce-b59bc51e3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## folder path containing 12 csv files. \n",
    "csv_folder = Path(r\"C:\\Users\\admin\\Downloads\\csv_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12658f7a-2651-434c-879e-aa45222fbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking: colors.csv\n",
      "24 null values found:\n",
      "y1    12\n",
      "y2    12\n",
      "dtype: int64\n",
      "\n",
      "Checking: elements.csv\n",
      "26382 null values found:\n",
      "design_id    26382\n",
      "dtype: int64\n",
      "\n",
      "Checking: inventories.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: inventory_minifigs.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: inventory_parts.csv\n",
      "6766 null values found:\n",
      "img_url    6766\n",
      "dtype: int64\n",
      "\n",
      "Checking: inventory_sets.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: minifigs.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: parts.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: part_categories.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: part_relationships.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: sets.csv\n",
      "No nulls found.\n",
      "\n",
      "Checking: themes.csv\n",
      "147 null values found:\n",
      "parent_id    147\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for csv_file in csv_folder.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    nulls = df.isnull().sum()\n",
    "    total = nulls.sum()\n",
    "    print(f\"\\nChecking: {csv_file.name}\")\n",
    "    if total == 0:\n",
    "        print(\"No nulls found.\")\n",
    "    else:\n",
    "        print(f\"{total} null values found:\")\n",
    "        print(nulls[nulls > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3320abb7-1e15-4cd5-b39a-e5fa89f4a234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "colors.csv\n",
      "nulls: 24\n",
      "y1    12\n",
      "y2    12\n",
      "dtype: int64\n",
      "saved\n",
      "\n",
      "elements.csv\n",
      "nulls: 26382\n",
      "design_id    26382\n",
      "dtype: int64\n",
      "saved\n",
      "\n",
      "inventories.csv\n",
      "no nulls\n",
      "\n",
      "inventory_minifigs.csv\n",
      "no nulls\n",
      "\n",
      "inventory_parts.csv\n",
      "nulls: 6766\n",
      "img_url    6766\n",
      "dtype: int64\n",
      "saved\n",
      "\n",
      "inventory_sets.csv\n",
      "no nulls\n",
      "\n",
      "minifigs.csv\n",
      "no nulls\n",
      "\n",
      "parts.csv\n",
      "no nulls\n",
      "\n",
      "part_categories.csv\n",
      "no nulls\n",
      "\n",
      "part_relationships.csv\n",
      "no nulls\n",
      "\n",
      "sets.csv\n",
      "no nulls\n",
      "\n",
      "themes.csv\n",
      "nulls: 147\n",
      "parent_id    147\n",
      "dtype: int64\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "for csv_file in csv_folder.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    nulls = df.isnull().sum()\n",
    "    total = nulls.sum()\n",
    "    print(f\"\\n{csv_file.name}\")\n",
    "    if total == 0:\n",
    "        print(\"no nulls\")\n",
    "    else:\n",
    "        print(f\"nulls: {total}\")\n",
    "        print(nulls[nulls > 0])\n",
    "        ## fill numeric columns with mean\n",
    "        for col in df.select_dtypes(include=[\"float64\", \"int64\"]):\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        ## fill object columns with mode\n",
    "        for col in df.select_dtypes(include=[\"object\"]):\n",
    "            mode = df[col].mode()\n",
    "            if not mode.empty:\n",
    "                df[col].fillna(mode[0], inplace=True)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc072dd7-125d-4cec-a676-66276ca94ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checking colors.csv\n",
      "no nulls\n",
      "\n",
      "checking elements.csv\n",
      "no nulls\n",
      "\n",
      "checking inventories.csv\n",
      "no nulls\n",
      "\n",
      "checking inventory_minifigs.csv\n",
      "no nulls\n",
      "\n",
      "checking inventory_parts.csv\n",
      "no nulls\n",
      "\n",
      "checking inventory_sets.csv\n",
      "no nulls\n",
      "\n",
      "checking minifigs.csv\n",
      "no nulls\n",
      "\n",
      "checking parts.csv\n",
      "no nulls\n",
      "\n",
      "checking part_categories.csv\n",
      "no nulls\n",
      "\n",
      "checking part_relationships.csv\n",
      "no nulls\n",
      "\n",
      "checking sets.csv\n",
      "no nulls\n",
      "\n",
      "checking themes.csv\n",
      "no nulls\n"
     ]
    }
   ],
   "source": [
    "## Now i Check again whether these null values have been filled mean, mode\n",
    "for csv_file in csv_folder.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    nulls = df.isnull().sum()\n",
    "    total = nulls.sum()\n",
    "    print(f\"\\nchecking {csv_file.name}\")\n",
    "    if total == 0:\n",
    "        print(\"no nulls\")\n",
    "    else:\n",
    "        print(f\"total nulls: {total}\")\n",
    "        print(nulls[nulls > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e5764-4cdf-4865-9893-49c1d7a1aac3",
   "metadata": {},
   "source": [
    "## Method 1: Insert Directly and Create tables in DB by loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0a2ecdd-a0a8-4545-a865-701e8ffd3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'LENOVO\\\\DAJANASQL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f24e374b-1a8f-46d2-a788-88ce4e12d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database = 'LEGO2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1239a99f-24d6-4d00-b4a2-4af2f509c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    f\"mssql+pyodbc://@{server}/{database}\"\n",
    "    \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes\"\n",
    "    \"&Encrypt=yes\"\n",
    "    \"&TrustServerCertificate=yes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aa5a995-5b21-431d-a816-1356085763f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7844d6a9-45d3-4c18-8ff9-074f55183255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server', 'Microsoft Access Driver (*.mdb, *.accdb)', 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)', 'Microsoft Access Text Driver (*.txt, *.csv)', 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)', 'Oracle in OraDB19Home1', 'MySQL ODBC 8.3 ANSI Driver', 'MySQL ODBC 8.3 Unicode Driver', 'ODBC Driver 17 for SQL Server']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "print(pyodbc.drivers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd096df4-f32f-4a12-807d-60a0a718b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting colors.csv into colors...\n",
      "done with colors\n",
      "Inserting elements.csv into elements...\n",
      "done with elements\n",
      "Inserting inventories.csv into inventories...\n",
      "done with inventories\n",
      "Inserting inventory_minifigs.csv into inventory_minifigs...\n",
      "done with inventory_minifigs\n",
      "Inserting inventory_parts.csv into inventory_parts...\n",
      "done with inventory_parts\n",
      "Inserting inventory_sets.csv into inventory_sets...\n",
      "done with inventory_sets\n",
      "Inserting minifigs.csv into minifigs...\n",
      "done with minifigs\n",
      "Inserting parts.csv into parts...\n",
      "done with parts\n",
      "Inserting part_categories.csv into part_categories...\n",
      "done with part_categories\n",
      "Inserting part_relationships.csv into part_relationships...\n",
      "done with part_relationships\n",
      "Inserting sets.csv into sets...\n",
      "done with sets\n",
      "Inserting themes.csv into themes...\n",
      "done with themes\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        table = Path(filename).stem\n",
    "        path = csv_folder / filename\n",
    "        print(f\"Inserting {filename} into {table}...\")\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            df.to_sql(table, con=engine, if_exists=\"fail\", index=False)\n",
    "            print(f\"done with {table}\")\n",
    "        except Exception as e:\n",
    "            print(f\"failed on {table}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c48697-f55f-4c96-bda7-b1264dc2fd29",
   "metadata": {},
   "source": [
    "## Method 2: Loading Data from csv Files into Database after having previously created tables with PKs Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67073148-cd7a-4f70-9cbc-69940f764b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'LEGO_Rebrickable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c4432af-a76f-4d59-9db1-abb08c66d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    f\"mssql+pyodbc://@{server}/{database}\"\n",
    "    \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes\"\n",
    "    \"&Encrypt=yes\"\n",
    "    \"&TrustServerCertificate=yes\"\n",
    "    \"&timeout=120\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5ce4b9-4b11-4e69-a59b-f81aade5a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(connection_string, fast_executemany=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23067252-2da8-4b41-b33e-2543a0b523a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_27660\\2384002670.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 'colors.csv' into table 'colors'...\n",
      "✅ Done inserting into colors\n",
      "Inserting 'elements.csv' into table 'elements'...\n",
      "✅ Done inserting into elements\n",
      "Inserting 'inventories.csv' into table 'inventories'...\n",
      "✅ Done inserting into inventories\n",
      "Inserting 'inventory_minifigs.csv' into table 'inventory_minifigs'...\n",
      "✅ Done inserting into inventory_minifigs\n",
      "Inserting 'inventory_parts.csv' into table 'inventory_parts'...\n",
      "✅ Done inserting into inventory_parts\n",
      "Inserting 'inventory_sets.csv' into table 'inventory_sets'...\n",
      "✅ Done inserting into inventory_sets\n",
      "Inserting 'minifigs.csv' into table 'minifigs'...\n",
      "✅ Done inserting into minifigs\n",
      "Inserting 'parts.csv' into table 'parts'...\n",
      "✅ Done inserting into parts\n",
      "Inserting 'part_categories.csv' into table 'part_categories'...\n",
      "✅ Done inserting into part_categories\n",
      "Inserting 'part_relationships.csv' into table 'part_relationships'...\n",
      "✅ Done inserting into part_relationships\n",
      "Inserting 'sets.csv' into table 'sets'...\n",
      "✅ Done inserting into sets\n",
      "Inserting 'themes.csv' into table 'themes'...\n",
      "✅ Done inserting into themes\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(csv_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        table = Path(filename).stem\n",
    "        path = csv_folder / filename\n",
    "        print(f\"inserting {filename} into {table}...\")\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            df.to_sql(table, con=engine, if_exists=\"append\", index=False, chunksize=1000)\n",
    "            print(f\"done with {table}\")\n",
    "        except Exception as e:\n",
    "            print(f\"couldn't insert into {table}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
